from typing import Union, List, Literal, Dict, Optional
import google.generativeai as genai
from google.generativeai.types import content_types

from dotenv import load_dotenv
import os
import json
from dataclasses import dataclass
from collections.abc import Iterable

from src.agent_utils import Agent_Base
from src.structuredb import ChatHistoryDB

@dataclass
class Answer:
    answer: str
    additional_content:str

@dataclass
class FinalAnswer:
    answers: List[Answer]

class Agent(Agent_Base):
    
    intent_prompt = f"""<start_of_turn>user\n
    **Instruction**
    Given the query of user, answer the question base on Thought, Action format. Thought can reason 
    about the current situation. Action can be one of three below tools:
    **Avaliable tools**
    {{tool_list_desription}}

    **Below are some examples showing a query, and output format:**
    {{examples}}    

    **Here is the main query of user to need to answer:**
    **Query**:
    {{query}}
    **Output:**
    <end_of_turn><eos>\n"""

    single_trajectory = f"""
    Thought: {{thought}}
    Action: {{action}}
    Action Input: {{action_input}}
    Observation: {{observation}}
"""
    final_answer_prompt = f"""
<start_of_turn>user\n
    - Base on below Thought, Action and Observation, let think step-by-step and give Final answer to the Question.
    - Collect any relevant information in Observation in `additional_content` to support your Final answer
    - Give Final answer in Vietnamese language.
    Question: {{query}}

    {{input_trajectory}}

    Final answer:
<end_of_turn><eos>\n
"""

    def __init__(self):
        super().__init__(tools = [self.search_facts, self.find_blogs, self.give_direct_answer])
        
        load_dotenv()
        genai.configure(api_key=os.environ['GOOGLE_API_KEY'])

        self.model = genai.GenerativeModel(
            model_name= "gemini-1.5-flash",
            system_instruction = "Your are professional travel recommender.",
        )

        self.chat_hist_db = ChatHistoryDB()

    def give_direct_answer(self, direct_answer:str)->str:
        """
        Direct take `direct_answer` generated by Gemini and return it.
        Use this function when you want to give direct answer based on query.
        Args:
            - direct_answer (str)
        Returns:
            a string exactly the same as input
        """
        return direct_answer

    def post_execute(self, reponse_dict: dict)->str:
        """
        Post processing for function calling, invoke selected tools
        Returns:
            formated trajectory
        """
        
        # consturct args
        exec_args = {arg['key']: arg['value'] for arg in reponse_dict['Action']['args']}

        # run tool
        _tool_results = self.func_name_to_func.get(reponse_dict['Action']['function_name'])(**exec_args)
        
        return self.single_trajectory.format(
            thought = reponse_dict['Thought'],
            action = reponse_dict['Action']['function_name'],
            action_input = exec_args,
            observation = _tool_results
        )
    
    def final_processing(self, reponse: Dict[str,str])->str:
        return reponse['answers']


    # history=[
    #     {"role": "user", "parts": "Hello"},
    #     {"role": "model", "parts": "Great to meet you. What would you like to know?"},
    # ]
    def __call__(self, prompt_data:str)->List[str]:
        # step 0
        init_prompt = self.intent_prompt.format(
            query = prompt_data,
            tool_list_desription = self.tool_list_desription,
            examples = self.examples,
        )
        
        # step 1.0: 
        response = self.model.generate_content(
            contents = init_prompt,
            generation_config = genai.GenerationConfig(
                max_output_tokens = 1000,
                temperature = 0.1
            )
        )
        # step 1.1
        post_answer_processing = response.text.replace('```json','').replace('```','')
        # step 2:
        trajectory = self.post_execute(reponse_dict = json.loads(post_answer_processing))
        # step 3:
        final_prompt = self.final_answer_prompt.format(
            query = prompt_data,
            tool_list_desription = self.tool_list_desription,
            input_trajectory = trajectory)
        
        print('final prompt: ', final_prompt)
        response = self.model.generate_content(
            contents = final_prompt,
            generation_config = genai.GenerationConfig(
                # max_output_tokens = 1000,
                # temperature = 0.1,
                response_mime_type = "application/json",
                response_schema=  FinalAnswer
            )
        )
        # step 4
        return self.final_processing(json.loads(response.text))